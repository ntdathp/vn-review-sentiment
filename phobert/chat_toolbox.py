#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Chat Toolbox GUI (PyQt6) ‚Äî Auto-load my_phobert_only.py, toggle PhoBERT <-> LLM (HTTP)
V2.7-patched ‚Äî N·ªõi gate ƒë·ªÉ tr√°nh skip v√¥ l√Ω c√°c review th·∫≠t (e-commerce, m·ªπ ph·∫©m‚Ä¶)
  ‚Ä¢ Th√™m nh·∫≠n di·ªán "review th·∫≠t" s·ªõm: c√≥ ‚â•2 t·ª´ n·ªôi dung (‚â•4 k√Ω t·ª±, c√≥ nguy√™n √¢m) + t·ª´ kh√≥a e-commerce ‚Üí KH√îNG skip
  ‚Ä¢ Kh√¥ng skip n·∫øu c√≥ c·ª•m v·∫≠n chuy·ªÉn/ƒë√≥ng g√≥i/th∆∞∆°ng hi·ªáu/ph·∫©m ch·∫•t ("giao h√†ng", "ƒë√≥ng g√≥i", "ch√≠nh h√£ng", "m√πi h∆∞∆°ng", "d∆∞·ª°ng ·∫©m"‚Ä¶)
  ‚Ä¢ H·∫° ƒë·ªô nh·∫°y c√°c rule g√¢y oan: 
      - repeated-short-token: c·∫ßn ‚â•4 l·∫ßn (tr∆∞·ªõc ƒë√¢y 3) v√† token chi·∫øm ‚â•60% t·ªïng token
      - many-very-short: c·∫ßn ‚â•4 token (tr∆∞·ªõc ƒë√¢y 3)
      - too-short-words: ch·ªâ √°p d·ª•ng khi tok_cnt ‚â§3 (tr∆∞·ªõc ƒë√¢y ‚â§4) v√† kh√¥ng c√≥ hint/lexicon
      - multi-token-gibberish: n·ªõi ng∆∞·ª°ng v√† b·ªè qua n·∫øu c√≥ pos/neg signal hay c·ª•m e-commerce
  ‚Ä¢ V·∫´n skip c√°c chu·ªói l·∫∑p v√¥ nghƒ©a ki·ªÉu "h√†i l√≤ng?" * 30, ho·∫∑c spam k√Ω t·ª±, ho·∫∑c t·ª•c tƒ©u
"""
from __future__ import annotations

import sys, os, traceback, importlib, importlib.util, html, json, re, unicodedata, string, math
from typing import Callable, Optional
from collections import Counter
from PyQt6 import QtCore, QtWidgets, QtGui

# ====== import textproc (file b·∫°n t·ª± code) ======
try:
    import textproc as tp
except Exception:
    tp = None  # v·∫´n ch·∫°y, ch·ªâ m·∫•t 1 s·ªë t√≠n hi·ªáu

# Optional: HTTP client for LLM
try:
    import requests
except Exception:
    requests = None

# Colors
YOU_COLOR   = "#6a1b9a"
MODEL_COLOR = "#1565c0"
INFO_COLOR  = "#2e7d32"
ERROR_COLOR = "#c62828"
TEXT_COLOR  = "#000000"

# -------------------------------
# Dynamic model loader
# -------------------------------
class ModelClient(QtCore.QObject):
    modelLoaded = QtCore.pyqtSignal(str)
    modelCleared = QtCore.pyqtSignal()
    def __init__(self, parent=None):
        super().__init__(parent)
        self._infer_fn: Optional[Callable[[str], str]] = None
        self._normalize_fn: Optional[Callable[[str], str]] = None
        self._module_name: Optional[str] = None
    def _load_from_module(self, module) -> None:
        infer_fn = getattr(module, "infer", None)
        if not callable(infer_fn):
            raise AttributeError("Module kh√¥ng ƒë·ªãnh nghƒ©a h√†m infer(text: str) -> str.")
        normalize_fn = getattr(module, "normalize", None)
        if normalize_fn is not None and not callable(normalize_fn):
            normalize_fn = None
        self._infer_fn = infer_fn
        self._normalize_fn = normalize_fn
    def load_from_module_name(self, name: str):
        module = importlib.import_module(name)
        self._load_from_module(module)
        self._module_name = name
        self.modelLoaded.emit(name)
    def clear(self):
        self._infer_fn = None
        self._normalize_fn = None
        self._module_name = None
        self.modelCleared.emit()
    def has_infer(self) -> bool:
        return callable(self._infer_fn)
    def has_normalize(self) -> bool:
        return callable(self._normalize_fn)
    def infer(self, text: str, use_normalize: bool = False) -> str:
        if not self.has_infer():
            return f"[echo] {text}"
        if use_normalize and self.has_normalize():
            try:
                text = self._normalize_fn(text)  # type: ignore[misc]
            except Exception:
                traceback.print_exc()
        return self._infer_fn(text)  # type: ignore[misc]

# -------------------------------
# Generic worker
# -------------------------------
class InferWorker(QtCore.QObject):
    started = QtCore.pyqtSignal(str)
    finished = QtCore.pyqtSignal(str, str)
    failed = QtCore.pyqtSignal(str)
    def __init__(self, runner: Callable[[str], str], text: str, parent=None):
        super().__init__(parent); self._runner = runner; self._text = text
    @QtCore.pyqtSlot()
    def run(self):
        try:
            self.started.emit(self._text)
            out = self._runner(self._text)
            if not isinstance(out, str): out = str(out)
            self.finished.emit(self._text, out)
        except Exception as e:
            self.failed.emit(f"{e}\n{traceback.format_exc()}")

# -------------------------------
# Main Window
# -------------------------------
class ChatWindow(QtWidgets.QMainWindow):
    # ===== Regex / dicts for low-info gate =====
    _VI_NONWORD = r"[^\w\s√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµƒë]"
    _PAT_ALO = re.compile(r"^\s*(alo[\s!?.]*){1,10}$", re.IGNORECASE)
    _PAT_REPEAT_SYL = re.compile(r"^(\w{1,6})(?:\s*\1){2,}$", re.UNICODE)  # ‚â•3 l·∫ßn t·ªïng

    _PROF_SET = {"cm","cmm","cml","dm","ƒëm","vl","vkl","cc","wtf","lol","shit","fuck","ƒë·ªãt","l·ªìn","c·∫∑c","ƒë√©o","m·∫π"}
    _PROF_RE  = re.compile(r"^(?:c+\.?m+(?:\.?l+)?|d+\.?m+|ƒë+\.?m+)$", re.IGNORECASE | re.UNICODE)

    # Hints: NGUY√äN T·ª™ (full-word) ‚Äî kh√¥ng d√πng substring
    _HINT_WORDS = {
        # danh m·ª•c / h√†ng ho√°
        "s·∫£n","ph·∫©m","s·∫£n ph·∫©m","san","pham","sanpham","h√†ng","hang","shop","sp","ƒë∆°n","don","order",
        # thu·ªôc t√≠nh / linh ki·ªán
        "pin","s·∫°c","sac","m√†n","h√¨nh","man","hinh","loa","tai","nghe","√¢m","bass","wifi","bluetooth",
        "·ªëp","op","mi·∫øng","d√°n","mieng","dan","√°o","qu·∫ßn","gi√†y","d√©p","ao","quan","giay","dep",
        # shorthands neutral
        "bt","bth",
        # m·ªπ ph·∫©m ph·ªï th√¥ng
        "son","m√¥i","mui","m√πi","d∆∞·ª°ng","duong","kem","lip","lipice","dhc","innisfree","cocoon"
    }

    # Short sentiment tokens (c√≥ & kh√¥ng d·∫•u)
    _SHORT_POS = {"t·ªët","tot","ok","oke","oki","·ªïn","on","ƒë·∫πp","dep","x·ªãn","xin","ung","∆∞ng"}
    _SHORT_NEG = {"t·ªá","te","x·∫•u","xau","k√©m","kem","ƒë·∫Øt","dat","ph√®n","phen","chan","ch√°n","d·ªü","d·ªüm","l·ªüm","dom","lom"}
    _SHORT_NEU = {"bt","bth"}

    # E-commerce review keywords (whitelist)
    _REVIEW_PHRASES = [
        r"giao\s*h√†ng", r"ƒë√≥ng\s*g√≥i", r"ch√≠nh\s*h√£ng", r"ƒë√∫ng\s*m√¥\s*t·∫£",
        r"m√πi\s*h∆∞∆°ng", r"th∆°m", r"d∆∞·ª°ng\s*·∫©m", r"m·ªãn\s*m√¥i", r"l√™n\s*m√†u",
        r"tem\s*ch·ªëng\s*h√†ng\s*gi·∫£", r"shipper", r"gi√°\s*(t·ªët|·ªïn|ok|h·ª£p\s*l√Ω|r·∫ª)",
        r"mua\s*l·∫°i|l·∫ßn\s*2|l·∫ßn\s*n·ªØa", r"bao\s*b√¨|ni√™m\s*phong|seal",
    ]
    _REVIEW_RE = [re.compile(pat, re.IGNORECASE | re.UNICODE) for pat in _REVIEW_PHRASES]

    # Ch·ªØ c√°i
    _CONSONANTS = set(chr(c) for c in range(97,123)) - set("aeiouy"); _CONSONANTS.update(list("ƒë"))
    _VOWELS = set("aeiouy")
    _VI_VOWELS_ALL = set("aƒÉ√¢e√™io√¥∆°u∆∞y√°√†·∫£√£·∫°·∫Ø·∫±·∫≥·∫µ·∫∑·∫•·∫ß·∫©·∫´·∫≠√©√®·∫ª·∫Ω·∫π·∫ø·ªÅ·ªÉ·ªÖ·ªá√≠√¨·ªâƒ©·ªã√≥√≤·ªè√µ·ªç·ªë·ªì·ªï·ªó·ªô·ªõ·ªù·ªü·ª°·ª£√∫√π·ªß≈©·ª•·ª©·ª´·ª≠·ªØ·ª±√Ω·ª≥·ª∑·ªπ·ªµ")  # ƒë·ªÉ b·∫Øt nguy√™n √¢m c√≥ d·∫•u
    _RARE_LATINS = set("fjwz")  # TV √≠t d√πng

    # Fallback t√≠ch c·ª±c/ti√™u c·ª±c ng·∫Øn (m·∫´u c√¢u)
    _LOCAL_POS_FALLBACK = [
        re.compile(r"\bx·ªãn\s*[sx][√≤o]\b", re.IGNORECASE),
        re.compile(r"\bqu√°\s*x·ªãn\b", re.IGNORECASE),
        re.compile(r"\bqu√°\s*ok(?:e+)?\b", re.IGNORECASE),
        re.compile(r"\bshop\s*(·ªïn|ok|oke|uy\s*t√≠n|nhi·ªát\s*t√¨nh)\b", re.IGNORECASE),
    ]
    _LOCAL_NEG_FALLBACK = [
        re.compile(r"\b(t·ªá|x·∫•u|k√©m|d·ªüm|l·ªüm|ƒë·∫Øt|ph√®n)\b", re.IGNORECASE),
        re.compile(r"\b(s·∫£n\s*ph·∫©m|sp|h√†ng|shop)\s+(r·∫•t\s+)?(t·ªá|x·∫•u|k√©m|d·ªüm|l·ªüm|ƒë·∫Øt|ph√®n)\b", re.IGNORECASE),
    ]

    # Generic tokens & function words (kh√¥ng d·∫•u)
    _GENERIC_TOKENS = {
        "san","pham","sanpham","hang","don","donhang","shop","sp","mh","item","items","order",
        "hanghoa","hang_hoa","san_pham","san-pham"
    }
    _FUNC_WORDS = {"nhu","la","thi","va","hoac","cua","vaÃÄ","laÃÄ"}

    def __init__(self):
        super().__init__()
        self.setWindowTitle("Chat Toolbox (PyQt6)")
        self.resize(1100, 680)
        self.setMinimumWidth(960)

        self.model = ModelClient(self)
        self.use_llm = False

        # ====== UI ======
        top_bar = QtWidgets.QHBoxLayout(); top_bar.setSpacing(8)
        self.btn_engine = QtWidgets.QPushButton("Engine: PhoBERT")
        self.btn_engine.setCheckable(True); self.btn_engine.setMinimumWidth(160)
        self.btn_engine.setStyleSheet("font-weight:600; padding:6px 10px;")
        self.btn_engine.setToolTip("ƒêang d√πng PhoBERT. B·∫•m ƒë·ªÉ chuy·ªÉn sang LLM (HTTP).")

        self.llm_opts = QtWidgets.QFrame(); self.llm_opts.setFrameShape(QtWidgets.QFrame.Shape.NoFrame)
        llm_layout = QtWidgets.QHBoxLayout(self.llm_opts); llm_layout.setContentsMargins(0,0,0,0); llm_layout.setSpacing(6)
        self.lbl_llm_model = QtWidgets.QLabel("Model:")
        self.cmb_llm_model = QtWidgets.QComboBox(); self.cmb_llm_model.setEditable(True)
        self.cmb_llm_model.addItems(["qwen3:8b","qwen2.5:7b-instruct","qwen2.5:14b-instruct"])
        self.cmb_llm_model.setCurrentText("qwen3:8b"); self.cmb_llm_model.setMinimumWidth(180)
        self.lbl_llm_url = QtWidgets.QLabel("URL:")
        self.txt_llm_url = QtWidgets.QLineEdit("http://localhost:11434/api/generate")
        self.txt_llm_url.setMinimumWidth(260); self.txt_llm_url.setPlaceholderText("http://<host>:<port>/api/generate")
        llm_layout.addWidget(self.lbl_llm_model); llm_layout.addWidget(self.cmb_llm_model)
        llm_layout.addWidget(self.lbl_llm_url); llm_layout.addWidget(self.txt_llm_url)
        self.llm_opts.hide()

        self.lbl_model = QtWidgets.QLabel("No model loaded"); self.lbl_model.setStyleSheet("color: gray;")

        top_bar.addWidget(self.btn_engine); top_bar.addWidget(self.llm_opts); top_bar.addStretch(1); top_bar.addWidget(self.lbl_model)

        central = QtWidgets.QWidget(self); self.setCentralWidget(central)
        main_layout = QtWidgets.QVBoxLayout(central); main_layout.setContentsMargins(10,10,10,10); main_layout.setSpacing(8)
        main_layout.addLayout(top_bar)

        self.history = QtWidgets.QTextEdit(); self.history.setReadOnly(True)
        self.history.setPlaceholderText("L·ªãch s·ª≠ h·ªôi tho·∫°i s·∫Ω hi·ªÉn th·ªã ·ªü ƒë√¢y‚Ä¶")
        self.history.setMinimumHeight(320); main_layout.addWidget(self.history, 1)

        input_row = QtWidgets.QHBoxLayout()
        self.input = QtWidgets.QPlainTextEdit()
        self.input.setPlaceholderText("Nh·∫≠p tin nh·∫Øn‚Ä¶ (Enter ƒë·ªÉ g·ª≠i, Shift+Enter ƒë·ªÉ xu·ªëng d√≤ng)")
        self.input.installEventFilter(self)
        self.btn_send = QtWidgets.QPushButton("Send"); self.btn_send.setDefault(True)
        self.btn_send.setCursor(QtGui.QCursor(QtCore.Qt.CursorShape.PointingHandCursor))
        input_row.addWidget(self.input, 1); input_row.addWidget(self.btn_send); main_layout.addLayout(input_row)

        bottom_bar = QtWidgets.QHBoxLayout(); bottom_bar.setSpacing(8); bottom_bar.setContentsMargins(0,0,0,0)
        self.btn_save = QtWidgets.QPushButton("Save Log‚Ä¶"); self.btn_clear_chat = QtWidgets.QPushButton("Clear Chat")
        bottom_bar.addWidget(self.btn_save); bottom_bar.addWidget(self.btn_clear_chat); bottom_bar.addStretch(1)
        self.status = QtWidgets.QLabel("Ready"); self.status.setStyleSheet("color: gray;"); self.status.setFixedWidth(90)
        bottom_bar.addWidget(self.status); main_layout.addLayout(bottom_bar)

        # Signals
        self.btn_send.clicked.connect(self.on_send)
        self.btn_save.clicked.connect(self.on_save_log)
        self.btn_clear_chat.clicked.connect(self.on_clear_chat)
        self.model.modelLoaded.connect(self.on_model_loaded)
        self.model.modelCleared.connect(self.on_model_cleared)
        self.btn_engine.toggled.connect(self._on_engine_toggled)

        self._active_threads: list[QtCore.QThread] = []

        # Auto-load model module
        mod_name = os.environ.get("CHAT_TOOLBOX_PHOBERT_MODULE", "my_phobert_only")
        try:
            self.model.load_from_module_name(mod_name)
        except Exception as e:
            self.append_error(f"Kh√¥ng th·ªÉ auto-load module '{mod_name}': {e}")
        print(">>> Chat Toolbox started. Engine: PhoBERT (default).")

        if tp is None:
            self.append_error("Kh√¥ng import ƒë∆∞·ª£c textproc.py ‚Äî gate v·∫´n ch·∫°y nh∆∞ng kh√¥ng d√πng ƒë∆∞·ª£c normalize/lexicon t·ª´ textproc.")

    # ---------- UI helpers ----------
    def _append_block(self, title_html: str, body_text: str):
        safe_body = html.escape(body_text)
        block = f"{title_html}<br><span style=\"color:{TEXT_COLOR}; white-space:pre-wrap;\">{safe_body}</span><br><br>"
        self.history.append(block)
    def append_user(self, text: str):
        self._append_block(f'<span style="color:{YOU_COLOR}; font-weight:600;">You:</span>', text)
    def append_model(self, text: str):
        self._append_block(f'<span style="color:{MODEL_COLOR}; font-weight:600;">Model:</span>', text)
    def append_info(self, text: str):
        self._append_block(f'<span style="color:{INFO_COLOR}; font-weight:600;">[Info]</span>', text)
    def append_error(self, text: str):
        self._append_block(f'<span style="color:{ERROR_COLOR}; font-weight:600;">[Error]</span>', text)

    # ---------- Helpers ----------
    def _canon_token(self, tok: str) -> str:
        return re.sub(r'(.)\1{2,}', r'\1\1', tok.lower())

    def _token_is_profanity(self, tok: str) -> bool:
        return (tok in self._PROF_SET) or bool(self._PROF_RE.match(tok))

    def _strip_diacritics_basic(self, s: str) -> str:
        s = unicodedata.normalize("NFD", s)
        s = s.replace("ƒë","d").replace("ƒê","D")
        s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")
        return unicodedata.normalize("NFC", s)

    def _consonant_ratio(self, s: str) -> float:
        if not s: return 0.0
        letters = [c for c in s.lower() if c.isalpha()]
        if not letters: return 0.0
        consonants = sum(1 for c in letters if (c in self._CONSONANTS))
        return consonants / len(letters)

    def _vowel_ratio(self, s: str) -> float:
        if not s: return 0.0
        letters = [c for c in s.lower() if c.isalpha()]
        if not letters: return 0.0
        nod = self._strip_diacritics_basic("".join(letters)).lower()
        vowels = sum(1 for c in nod if c in set("aeiouy"))
        return vowels / len(letters)

    def _has_repeating_chunk(self, s: str) -> bool:
        if len(s) < 6: return False
        for k in (2, 3, 4):
            m = re.search(rf"([a-z0-9]{{{k}}})\1+", s.lower())
            if m: return True
        return False

    def _is_vowel_only_short(self, s: str) -> bool:
        s = s.strip(string.punctuation)
        if not s:
            return False
        letters = [ch for ch in s.lower() if ch.isalpha()]
        if not letters or len(letters) > 3:
            return False
        # True n·∫øu t·∫•t c·∫£ l√† nguy√™n √¢m (k·ªÉ c·∫£ c√≥ d·∫•u)
        return all(ch in self._VI_VOWELS_ALL for ch in letters)

    def _norm_words(self, text: str):
        nod = (tp.strip_accents_simple(text) if tp else self._strip_diacritics_basic(text))
        return re.findall(r"[A-Za-z√Ä-·ªπ√†-·ªπ0-9]+", nod)

    def _is_product_hint_token(self, tok: str) -> bool:
        t = tok.strip().lower()
        if not t: return False
        t = t.strip(string.punctuation)
        if not t: return False
        t_nod = self._strip_diacritics_basic(t)
        return (t in self._HINT_WORDS) or (t_nod in self._HINT_WORDS)

    def _is_short_sentiment_token(self, tok: str) -> bool:
        t = tok.strip().lower()
        if not t: return False
        t = t.strip(string.punctuation)
        if not t: return False
        t_nod = self._strip_diacritics_basic(t)
        return (t in self._SHORT_POS or t in self._SHORT_NEG or t in self._SHORT_NEU
                or t_nod in self._SHORT_POS or t_nod in self._SHORT_NEG or t_nod in self._SHORT_NEU)

    def _has_vi_vowel(self, s: str) -> bool:
        return any(ch.lower() in self._VI_VOWELS_ALL for ch in s)

    def _contains_review_phrase(self, text: str) -> bool:
        return any(p.search(text) for p in self._REVIEW_RE)

    def _content_tokens(self, text: str) -> int:
        words = re.findall(r"[A-Za-z√Ä-·ªπ√†-·ªπ0-9]+", text, re.UNICODE)
        cnt = 0
        for w in words:
            if len(w) >= 4 and self._has_vi_vowel(w) and not self._token_is_gibberish(w):
                cnt += 1
        return cnt

    def _looks_like_real_review(self, text: str) -> bool:
        # C√≥ √≠t nh·∫•t 2 t·ª´ n·ªôi dung + c·ª•m e-commerce ph·ªï bi·∫øn
        if len(text) >= 15 and self._content_tokens(text) >= 2 and self._contains_review_phrase(text.lower()):
            return True
        # Ho·∫∑c c√≥ ‚â•3 c√¢u ng·∫Øn c√°ch nhau b·∫±ng d·∫•u ch·∫•m, m·ªói c√¢u c√≥ t·ª´ ‚â•4 k√Ω t·ª± c√≥ nguy√™n √¢m
        sentences = [s.strip() for s in re.split(r"[.!?]+", text) if s.strip()]
        if len(sentences) >= 3:
            good = sum(any(len(w) >= 4 and self._has_vi_vowel(w) for w in re.findall(r"\w+", s)) for s in sentences)
            if good >= 2:
                return True
        return False

    def _token_is_gibberish(self, t: str) -> bool:
        if not t: return True
        core = t.strip(string.punctuation)
        if not core: return True

        letters = sum(ch.isalpha() for ch in core)
        digits  = sum(ch.isdigit() for ch in core)
        if digits > 0 and letters < 3 and len(core) >= 5:
            return True

        nod = (tp.strip_accents_simple(core) if tp else self._strip_diacritics_basic(core))
        cons_ratio = self._consonant_ratio(nod); vow_ratio = self._vowel_ratio(nod)

        # token 1‚Äì2 k√Ω t·ª±: n·∫øu kh√¥ng c√≥ nguy√™n √¢m & kh√¥ng ph·∫£i hint/sentiment => r√°c
        if 1 <= len(core) <= 2:
            if (not self._has_vi_vowel(core)) and (not self._is_product_hint_token(core)) and (not self._is_short_sentiment_token(core)):
                return True

        # token 3‚Äì4 k√Ω t·ª±, vowel_ratio r·∫•t th·∫•p v√† kh√¥ng ph·∫£i hint/sentiment -> r√°c
        if 3 <= len(nod) <= 4 and vow_ratio <= 0.25:
            if not (self._is_product_hint_token(core) or self._is_short_sentiment_token(core)):
                return True

        # token d√†i c√≥ ch·ªØ hi·∫øm (f/j/w/z) v√† kh√¥ng ph·∫£i hint/sentiment -> r√°c
        if len(nod) >= 5 and any(c in self._RARE_LATINS for c in nod):
            if not (self._is_product_hint_token(core) or self._is_short_sentiment_token(core)):
                return True

        # ch·ªØ 'q' ri√™ng: n·∫øu kh√¥ng ph·∫£i "qu" ·ªü ƒë·∫ßu => nghi r√°c khi token ng·∫Øn
        if len(nod) <= 4 and "q" in nod and not nod.startswith("qu"):
            if not (self._is_product_hint_token(core) or self._is_short_sentiment_token(core)):
                return True

        # 3+ ph·ª• √¢m li√™n ti·∫øp ‚Üí nghi r√°c
        if re.search(r"[^aeiouy\d]{3,}", nod) and len(nod) >= 5:
            return True

        # l·∫∑p chunk / qu√° nhi·ªÅu ph·ª• √¢m / qu√° √≠t nguy√™n √¢m
        if len(nod) >= 5 and (self._has_repeating_chunk(nod) or cons_ratio >= 0.75 or vow_ratio <= 0.18):
            return True

        # kh√¥ng l√† hint v√† nguy√™n √¢m c·ª±c th·∫•p
        if len(nod) >= 6 and (not self._is_product_hint_token(core)) and vow_ratio <= 0.15:
            return True

        return False

    # Tautology & generic-only
    def _is_tautology_like(self, text: str) -> bool:
        nod = (tp.strip_accents_simple(text) if tp else self._strip_diacritics_basic(text)).lower()
        nod = re.sub(r"\s+", " ", nod).strip()
        if re.search(r"\b([a-z0-9]{2,}(?:\s+[a-z0-9]{2,}){0,3})\s+(nhu|la|thi)\s+\1\b", nod):
            return True
        toks = re.findall(r"[a-z0-9]+", nod)
        if toks and all(t in self._GENERIC_TOKENS or t in self._FUNC_WORDS for t in toks):
            return True
        return False

    # Generic + Gibberish (c√¢u ng·∫Øn)
    def _is_generic_plus_gibberish(self, text: str) -> bool:
        toks = self._norm_words(text)
        if not toks: return False
        generic_or_func = [t for t in toks if (t in self._GENERIC_TOKENS or t in self._FUNC_WORDS)]
        others = [t for t in toks if t not in self._GENERIC_TOKENS and t not in self._FUNC_WORDS]
        gib_cnt = sum(self._token_is_gibberish(x) for x in others if not self._is_product_hint_token(x))
        if gib_cnt >= 1 and len(others) <= 2 and len(generic_or_func) >= max(1, len(toks) - len(others)):
            return True
        return False

    def _sig_stats(self, text: str):
        t = text.strip()
        if not t: return 0.0, 0.0, 1.0, 0, 0, [], [], 0.0, 0.0
        letters = sum(ch.isalpha() for ch in t)
        syms = len(re.findall(self._VI_NONWORD, t))
        alpha_ratio = letters / max(len(t), 1)
        uniq_ratio = len(set(t)) / max(len(t), 1)
        toks = re.findall(r"\w+", t.lower(), re.UNICODE)
        toks_c = [self._canon_token(x) for x in toks]
        tok_cnt = len(toks_c)
        bad_flags = [self._token_is_profanity(x) for x in toks_c]
        bad_tok_cnt = sum(bad_flags)
        sym_ratio = syms / max(len(t), 1)
        avg_len = (sum(len(x) for x in toks_c) / tok_cnt) if tok_cnt else 0.0
        prof_ratio = (bad_tok_cnt / tok_cnt) if tok_cnt else 0.0
        return alpha_ratio, uniq_ratio, sym_ratio, tok_cnt, bad_tok_cnt, toks_c, toks, avg_len, prof_ratio

    def _is_low_info(self, text: str):
        """
        Tr·∫£ v·ªÅ (True/False, reason_key, reason_msg).
        """
        t = re.sub(r"\s+", " ", text).strip()
        if t == "": return True, "empty", "VƒÉn b·∫£n tr·ªëng."
        if self._PAT_ALO.match(t): return True, "greeting/test-mic", "Chu·ªói ch√†o/ki·ªÉm tra micro, kh√¥ng ƒë·ªß ng·ªØ c·∫£nh."
        if self._PAT_REPEAT_SYL.match(t.replace(".", "").replace("!", "").lower()):
            return True, "repeated-syllables", "Chu·ªói l·∫∑p √¢m ti·∫øt, kh√¥ng ch·ª©a √Ω ki·∫øn v·ªÅ s·∫£n ph·∫©m."
        if self._is_tautology_like(t):
            return True, "tautology", "C√¢u l·∫∑p l·∫°i c√πng m·ªôt c·ª•m (v√≠ d·ª•: 'X nh∆∞ X'), kh√¥ng ch·ª©a nh·∫≠n x√©t."

        # ==== NEW: Nh·∫≠n di·ªán review th·∫≠t s·ªõm ====
        if self._looks_like_real_review(t):
            return False, "", ""

        # 1 token c·ª±c nhi·ªÖu
        if self._is_single_token_noise(t):
            return True, "single-token-gibberish", "VƒÉn b·∫£n v√¥ nghƒ©a: 1 t·ª´ kh√¥ng c√≥ n·ªôi dung ƒë√°nh gi√°."

        # Generic + Gibberish ng·∫Øn
        if self._is_generic_plus_gibberish(t):
            return True, "generic+gibberish", "Ch·ªâ ch·ª©a t·ª´ chung + 1‚Äì2 t·ª´ v√¥ nghƒ©a, kh√¥ng c√≥ nh·∫≠n x√©t."

        alpha_ratio, uniq_ratio, sym_ratio, tok_cnt, bad_tok_cnt, toks_c, toks, avg_len, prof_ratio = self._sig_stats(t)

        # ===== PRIORITY: n·∫øu c√≥ (product-hint) + (short-sentiment) => gi·ªØ l·∫°i =====
        if 2 <= tok_cnt <= 6:
            has_hint = any(self._is_product_hint_token(w) for w in toks_c)
            has_short_senti = any(self._is_short_sentiment_token(w) for w in toks_c)
            if has_hint and has_short_senti:
                return False, "", ""

        # textproc lexicon signals (n·∫øu c√≥)
        t_norm = tp.normalize_text(t) if tp else t
        try:
            pos_sig, neg_sig = tp.count_lexicon(t_norm) if tp else (0, 0)
        except Exception:
            pos_sig, neg_sig = (0, 0)

        # LOCAL fallback: t√≠ch c·ª±c & ti√™u c·ª±c ng·∫Øn (pattern)
        if pos_sig == 0 and neg_sig == 0:
            for pat in self._LOCAL_POS_FALLBACK:
                if pat.search(t): pos_sig = 1; break
        if pos_sig == 0 and neg_sig == 0:
            for pat in self._LOCAL_NEG_FALLBACK:
                if pat.search(t): neg_sig = 1; break

        # ===== Bag of noise: sau khi b·ªè hint/sentiment kh√¥ng c√≤n token c√≥ nguy√™n √¢m =====
        word_toks = re.findall(r"[A-Za-z√Ä-·ªπ√†-·ªπ0-9]+", t, re.UNICODE)
        non_hint2 = [w for w in word_toks if not (self._is_product_hint_token(w) or self._is_short_sentiment_token(w))]
        if non_hint2 and not any(self._has_vi_vowel(w) for w in non_hint2):
            return True, "no-vowel-nonhint", "Kh√¥ng c√≥ t·ª´ mang nguy√™n √¢m/√Ω nghƒ©a sau khi lo·∫°i t·ª´ g·ª£i √Ω."

        # ===== Multi-token gibberish (n·ªõi nh·∫π): 2‚Äì12 token =====
        if 2 <= len(word_toks) <= 12:
            non_hint = [w for w in word_toks
                        if not (self._is_product_hint_token(w) or self._is_short_sentiment_token(w))]
            if non_hint:
                gib_flags    = [self._token_is_gibberish(w) for w in non_hint]
                filler_flags = [self._is_vowel_only_short(w) for w in non_hint]  # v√≠ d·ª•: "oi", "ai", "∆°i"
                gib_cnt      = sum(gib_flags)
                filler_cnt   = sum(filler_flags)
                gib_ratio    = gib_cnt / max(1, len(non_hint))

                need = max(2, math.ceil(0.7 * len(non_hint)))  # tr∆∞·ªõc 0.6 ‚Üí tƒÉng 0.7 ƒë·ªÉ b·ªõt nh·∫°y

                if (
                    (gib_cnt >= need or gib_ratio >= (3/4) or (gib_cnt >= 2 and filler_cnt >= 1 and len(word_toks) <= 4))
                    and not self._contains_review_phrase(t.lower())
                    and (pos_sig == 0 and neg_sig == 0)
                ):
                    return True, "multi-token-gibberish", "C√°c t·ª´ ch·ªß y·∫øu v√¥ nghƒ©a, kh√¥ng c√≥ n·ªôi dung ƒë√°nh gi√°."

        # L·∫∑p h·∫°t ng·∫Øn (‚â§3) ‚â•4 l·∫ßn *v√†* chi·∫øm ‚â•60% token
        short_non_hint = [w.lower() for w in word_toks if (len(w) <= 3 and not self._is_product_hint_token(w) and not self._is_short_sentiment_token(w))]
        if short_non_hint:
            tok_most, n_most = Counter(short_non_hint).most_common(1)[0]
            if n_most >= 4 and n_most >= 0.6 * max(1, len(word_toks)) and (pos_sig == 0 and neg_sig == 0):
                return True, "repeated-short-token", "L·∫∑p t·ª´ r·∫•t ng·∫Øn qu√° nhi·ªÅu, thi·∫øu n·ªôi dung."

        # ‚â•4 token r·∫•t ng·∫Øn (‚â§2) kh√¥ng c√≥ nguy√™n √¢m
        very_short_no_vowel = sum(1 for w in word_toks if len(w) <= 2 and not self._has_vi_vowel(w))
        if very_short_no_vowel >= 4 and (pos_sig == 0 and neg_sig == 0):
            return True, "many-very-short", "Qu√° nhi·ªÅu t·ª´ c·ª±c ng·∫Øn kh√¥ng c√≥ nguy√™n √¢m, thi·∫øu n·ªôi dung."

        # Repeated token t·ªïng qu√°t: y√™u c·∫ßu m·∫°nh h∆°n
        if tok_cnt >= 3:
            tok_most2, n_most2 = Counter([w for w in re.findall(r"\w+", t.lower())]).most_common(1)[0]
            if n_most2 >= 4 and (len(tok_most2) <= 6 or self._token_is_profanity(tok_most2)) and (pos_sig == 0 and neg_sig == 0):
                return True, "repeated-token", "L·∫∑p m·ªôt t·ª´ nhi·ªÅu l·∫ßn, thi·∫øu n·ªôi dung."

        # profanity-only / mostly profanity
        if (1 <= tok_cnt <= 6) and (prof_ratio >= 0.6) and pos_sig == 0 and neg_sig == 0:
            return True, "mostly-profanity", "Ph·∫ßn l·ªõn t·ª´ ng·ªØ l√† t·ª•c tƒ©u, thi·∫øu n·ªôi dung ƒë√°nh gi√°."

        # C√¢u to√†n t·ª´ r·∫•t ng·∫Øn ‚Üí ch·ªâ khi r·∫•t √≠t t·ª´
        if tok_cnt <= 3 and avg_len <= 3 and pos_sig == 0 and neg_sig == 0 and not any(self._is_product_hint_token(w) for w in toks_c):
            return True, "too-short-words", "C√°c t·ª´ qu√° ng·∫Øn, kh√¥ng ƒë·ªß ng·ªØ c·∫£nh."

        # Letters ratio th·∫•p m√† kh√¥ng c√≥ t√≠n hi·ªáu n·ªôi dung
        if alpha_ratio < 0.40 and pos_sig == 0 and neg_sig == 0 and not any(self._is_product_hint_token(w) for w in toks_c):
            return True, "too-few-letters", "T·ª∑ l·ªá ch·ªØ c√°i qu√° th·∫•p, thi·∫øu n·ªôi dung."

        # K√Ω hi·ªáu nhi·ªÅu + ng·∫Øn
        if sym_ratio > 0.35 and len(t) < 30 and pos_sig == 0 and neg_sig == 0:
            return True, "too-many-symbols", "K√Ω hi·ªáu/emoji qu√° nhi·ªÅu, thi·∫øu n·ªôi dung."

        # ƒêa d·∫°ng k√Ω t·ª± th·∫•p + c√¢u ng·∫Øn
        if uniq_ratio < 0.15 and len(t) < 20 and pos_sig == 0 and neg_sig == 0:
            return True, "low-variance", "ƒêa d·∫°ng k√Ω t·ª± r·∫•t th·∫•p, nghi ng·ªù v√¥ nghƒ©a."

        # ƒê·∫∑c bi·ªát: 'bt/bth' ƒëi c√πng danh t·ª´ s·∫£n ph·∫©m => gi·ªØ l·∫°i (neutral)
        if any(w in {"bt","bth"} for w in toks_c) and any(self._is_product_hint_token(w) for w in toks_c):
            return False, "", ""

        return False, "", ""

    def _is_single_token_noise(self, text: str) -> bool:
        toks = re.findall(r"\w+", text.strip().lower(), re.UNICODE)
        if len(toks) != 1: return False
        t0 = toks[0]
        if self._is_product_hint_token(t0):
            return False
        L = len(t0)
        nod = (tp.strip_accents_simple(t0) if tp else self._strip_diacritics_basic(t0))
        dia_ratio = (tp.approx_diacritic_ratio(t0) if tp else 0.0)
        cons_ratio = self._consonant_ratio(nod); vow_ratio = self._vowel_ratio(nod)
        letters = sum(ch.isalpha() for ch in t0); digits = sum(ch.isdigit() for ch in t0)
        if digits > 0 and letters < 3 and L >= 5:
            return True
        if L >= 12: return True
        if 6 <= L <= 11:
            if self._has_repeating_chunk(nod): return True
            if cons_ratio >= 0.75: return True
            if dia_ratio < 0.05: return True
        if 3 <= L <= 5 and (vow_ratio <= 0.25 or re.search(r"[^aeiouy\d]{3,}", nod)):
            return True
        # Th√™m: 1‚Äì2 k√Ω t·ª± kh√¥ng c√≥ nguy√™n √¢m => r√°c
        if 1 <= L <= 2 and not self._has_vi_vowel(t0):
            return True
        return False

    # ---------- Engine toggle ----------
    def _on_engine_toggled(self, checked: bool):
        self.use_llm = checked
        if checked:
            self.btn_engine.setText("Engine: LLM (HTTP)")
            self.btn_engine.setToolTip("ƒêang d√πng LLM (HTTP). B·∫•m ƒë·ªÉ chuy·ªÉn v·ªÅ PhoBERT.")
            self.llm_opts.show()
        else:
            self.btn_engine.setText("Engine: PhoBERT")
            self.btn_engine.setToolTip("ƒêang d√πng PhoBERT. B·∫•m ƒë·ªÉ chuy·ªÉn sang LLM (HTTP).")
            self.llm_opts.hide()

    # ---------- LLM HTTP classify ----------
    # ---------- LLM HTTP classify ----------
    def _classify_llm_runner(self, url: str, model: str) -> Callable[[str], str]:
        LABELS = {"very_positive", "positive", "neutral", "negative", "very_negative"}

        def _normalize_str(s: str) -> str:
            s = unicodedata.normalize("NFKC", s)
            return s.strip().lower()

        # alias ƒë·ªÉ b·∫Øt m·∫•y ki·ªÉu vi·∫øt kh√°c / ti·∫øng Vi·ªát
        alias_map = {
            "very positive": "very_positive",
            "verypositive": "very_positive",
            "r·∫•t t·ªët": "very_positive",
            "tuy·ªát v·ªùi": "very_positive",

            "positive": "positive",
            "t·ªët": "positive",
            "good": "positive",

            "neutral": "neutral",
            "trung t√≠nh": "neutral",
            "b√¨nh th∆∞·ªùng": "neutral",
            "binh thuong": "neutral",
            "·ªïn": "neutral",
            "on": "neutral",

            "negative": "negative",
            "negativ": "negative",
            "x·∫•u": "negative",
            "bad": "negative",

            "very negative": "very_negative",
            "verynegative": "very_negative",
            "r·∫•t t·ªá": "very_negative",
            "kinh kh·ªßng": "very_negative",
            "t·ªìi t·ªá": "very_negative",
        }

        def _extract_label(raw: str) -> str:
            """C·ªë l·∫•y ra 1 nh√£n trong LABELS t·ª´ chu·ªói model tr·∫£ v·ªÅ."""
            if not raw:
                return "neutral"
            s = _normalize_str(raw)

            # 1) n·∫øu trong string c√≥ tr·ª±c ti·∫øp nh√£n chu·∫©n
            for lab in LABELS:
                if lab in s:
                    return lab

            # 2) n·∫øu match alias (ti·∫øng Vi·ªát / vi·∫øt th∆∞·ªùng)
            for key, lab in alias_map.items():
                if key in s:
                    return lab

            # 3) t√°ch token ch·ªØ c√°i / underscore, th·ª≠ t·ª´ng token
            tokens = re.findall(r"[a-z_]+", s)
            for tok in tokens:
                t = _normalize_str(tok).replace("-", "_").strip("._ ")
                if t in alias_map:
                    return alias_map[t]
                if t in LABELS:
                    return t

            # b√≥ tay th√¨ cho neutral
            return "neutral"

        SYSTEM_PROMPT = (
            "B·∫°n l√† b·ªô ph√¢n lo·∫°i c·∫£m x√∫c b√¨nh lu·∫≠n s·∫£n ph·∫©m ti·∫øng Vi·ªát.\n"
            "Nh√£n h·ª£p l·ªá: very_positive, positive, neutral, negative, very_negative.\n\n"
            "Nhi·ªám v·ª•:\n"
            "- ƒê·ªçc b√¨nh lu·∫≠n s·∫£n ph·∫©m.\n"
            "- Ch·ªçn M·ªòT nh√£n duy nh·∫•t th·ªÉ hi·ªán c·∫£m x√∫c t·ªïng th·ªÉ.\n"
            "- CH·ªà tr·∫£ v·ªÅ ƒë√∫ng M·ªòT t·ª´ trong c√°c t·ª´ sau (kh√¥ng th√™m b·∫•t k·ª≥ ch·ªØ n√†o kh√°c):\n"
            "very_positive\npositive\nneutral\nnegative\nvery_negative\n"
        )

        def _runner(text: str) -> str:
            if requests is None:
                raise RuntimeError("Thi·∫øu th∆∞ vi·ªán 'requests'. H√£y c√†i: pip install requests")

            prompt = f"{SYSTEM_PROMPT}\n\nB√¨nh lu·∫≠n: \"{text}\"\nNh√£n:"

            payload = {
                "model": model,
                "prompt": prompt,
                "stream": False,
                # üëá infer xong l√† unload model kh·ªèi RAM/GPU
                "keep_alive": 0,
                "options": {
                    "temperature": 0,
                    "top_p": 1,
                    "seed": 42,
                    "num_ctx": 2048,
                },
            }

            r = requests.post(url, json=payload, timeout=120)
            r.raise_for_status()
            out = r.json().get("response", "").strip()

            label = _extract_label(out)
            return f"LLM label: {label}"

        return _runner


    # ---------- Clear chat ----------
    def on_clear_chat(self):
        self.history.clear(); self.input.clear()
        self.status.setText("Cleared"); self.status.setStyleSheet("color: gray;")
        self.append_info("ƒê√£ xo√° to√†n b·ªô h·ªôi tho·∫°i.")

    # ---------- Events ----------
    def eventFilter(self, obj, event):
        if obj is self.input and event.type() == QtCore.QEvent.Type.KeyPress:
            key_event: QtGui.QKeyEvent = event  # type: ignore[assignment]
            if key_event.key() in (QtCore.Qt.Key.Key_Return, QtCore.Qt.Key.Key_Enter):
                if key_event.modifiers() & QtCore.Qt.KeyboardModifier.ShiftModifier:
                    return False
                self.on_send(); return True
        return super().eventFilter(obj, event)

    # ---------- Slots ----------
    def on_model_loaded(self, name: str):
        self.lbl_model.setText(f"Loaded: {name}"); self.lbl_model.setStyleSheet("color: #2e7d32;")
        if self.model.has_normalize():
            self.append_info("Module c√≥ normalize(). B·∫°n c√≥ th·ªÉ b·∫≠t 'Use normalizer' (n·∫øu c·∫ßn).")
        else:
            self.append_info("Module kh√¥ng c√≥ normalize(). S·∫Ω ch·ªâ d√πng infer().")

    def on_model_cleared(self):
        self.lbl_model.setText("No model loaded"); self.lbl_model.setStyleSheet("color: gray;")

    def on_send(self):
        text = self.input.toPlainText().strip()
        if not text: return
        self.append_user(text); self.input.clear()

        is_bad, _, reason_msg = self._is_low_info(text)
        if is_bad:
            skipped = (
                f"Text: {text}\n"
                f"Pred: <skipped>\n"
                f"Note: B·ªè qua ƒë·∫ßu v√†o ‚Äî {reason_msg}\n"
                f"Hint: H√£y nh·∫≠p c√¢u c√≥ n·ªôi dung ƒë√°nh gi√° s·∫£n ph·∫©m (vd: 'Ch·∫•t l∆∞·ª£ng ·ªïn, bass h∆°i y·∫øu')."
            )
            self.append_model(skipped)
            self.status.setText("Ready"); self.status.setStyleSheet("color: gray;")
            return

        self.status.setText("Running‚Ä¶"); self.status.setStyleSheet("color: #1565c0;")

        if self.use_llm:
            url = self.txt_llm_url.text().strip()
            model = self.cmb_llm_model.currentText().strip()
            runner = self._classify_llm_runner(url=url, model=model)
        else:
            runner = lambda t: self.model.infer(t, use_normalize=False)

        th = QtCore.QThread(self)
        worker = InferWorker(runner, text)
        worker.moveToThread(th)
        th.started.connect(worker.run)
        worker.finished.connect(self.on_infer_finished)
        worker.failed.connect(self.on_infer_failed)
        worker.finished.connect(lambda *_: self._finish_thread(th, worker))
        worker.failed.connect(lambda *_: self._finish_thread(th, worker))
        th.start(); self._active_threads.append(th)

    def _finish_thread(self, th: QtCore.QThread, worker: InferWorker):
        th.quit(); th.wait(2000)
        try: self._active_threads.remove(th)
        except ValueError: pass
        worker.deleteLater(); th.deleteLater()

    @QtCore.pyqtSlot(str, str)
    def on_infer_finished(self, input_text: str, output_text: str):
        self.append_model(output_text)
        self.status.setText("Ready"); self.status.setStyleSheet("color: gray;")

    @QtCore.pyqtSlot(str)
    def on_infer_failed(self, err: str):
        self.append_error(err)
        self.status.setText("Failed"); self.status.setStyleSheet("color: #c62828;")

    def on_save_log(self):
        path, _ = QtWidgets.QFileDialog.getSaveFileName(self, "L∆∞u h·ªôi tho·∫°i", "chat_log.txt", "Text Files (*.txt)")
        if not path: return
        try:
            with open(path, "w", encoding="utf-8") as f:
                f.write(self.history.toPlainText())
        except Exception as e:
            self.append_error(f"Kh√¥ng th·ªÉ l∆∞u: {e}")
        else:
            self.append_info(f"ƒê√£ l∆∞u: {path}")

def main():
    cwd = os.path.dirname(os.path.abspath(__file__))
    if cwd not in sys.path: sys.path.insert(0, cwd)
    app = QtWidgets.QApplication(sys.argv)
    win = ChatWindow(); win.show()
    sys.exit(app.exec())

if __name__ == "__main__":
    main()
